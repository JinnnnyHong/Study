{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJA4V0eLdW/f+RmeQG7uvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinnnnyHong/Study/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%98%88%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow와 Keras를 사용하는 MNIST 데이터셋으로 숫자 분류 문제"
      ],
      "metadata": {
        "id": "Uh5kbdkwHHiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. TensorFlow와 Keras를 사용하기 위해 모듈을 불러오기 \n",
        "\n",
        "2. MNIST 데이터셋을 불러오기. (keras.datasets.mnist.load_data()를 이용하여 데이터셋을 불러올 수 있음.)\n",
        "\n",
        "3. 데이터셋은 train set과 test set으로 나뉘어져 있음. (train set은 모델을 학습시키는 데 사용되고, test set은 모델의 일반화 성능을 평가하는 데 사용됨.)\n",
        "\n",
        "4. 데이터를 전처리 / 각 이미지 데이터는 0부터 255까지의 값을 가짐, 255로 나누어 정규화함(모델이 학습하는 과정에서 데이터의 범위를 비슷하게 만들어 주기 위해서)"
      ],
      "metadata": {
        "id": "7fntoOAgHR23"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcZW4m1YHDEs",
        "outputId": "02207714-e156-484f-e210-24156ecb4be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 설계하는 과정\n",
        "\n",
        "1) Sequential 모델 사용\n",
        "\n",
        " Sequential 모델은 층을 차례로 쌓아서 만드는 모델, \n",
        "\n",
        "첫 번째 층: 입력층으로, 입력 데이터의 형태를 정의,\n",
        "\n",
        "두 번째 층: 2차원 이미지 데이터를 1차원으로 평탄화하는 Flatten 층\n",
        "\n",
        "Flatten 층 이후:  Dense 층이 차례로 나오는데, 이 층들은 모두 fully connected 층임\n",
        "\n",
        "첫 번째 Dense 층은 128개의 뉴런을 가지며, 활성화 함수로 relu 함수 사용\n",
        "\n",
        "마지막 Dense 층은 출력층으로, 출력값이 10개인 softmax 함수 사용\n",
        "\n",
        " softmax 함수는 출력값을 각 클래스에 속할 확률로 나타내 줌\n",
        "\n"
      ],
      "metadata": {
        "id": "b3LxoWvIHyFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 설계\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "6U_21pXjH1-7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 컴파일하는 과정\n",
        "\n",
        "컴파일하는 과정에서는 최적화 알고리즘, 손실 함수, 평가 지표를 정의\n",
        "\n",
        "이 코드에서는 Adam 최적화 알고리즘을 사용하며, 손실 함수로 sparse_categorical_crossentropy 사용 \n",
        "\n",
        "평가 지표로는 accuracy 사용"
      ],
      "metadata": {
        "id": "dPRD9HhNIaOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ESx-Prw3Ianx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBjPjveJIbe_",
        "outputId": "94d58719-e906-4621-af03-a2ae178d7b98"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.2575 - accuracy: 0.9274 - val_loss: 0.1315 - val_accuracy: 0.9610\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1137 - accuracy: 0.9671 - val_loss: 0.0966 - val_accuracy: 0.9722\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0770 - accuracy: 0.9769 - val_loss: 0.0833 - val_accuracy: 0.9744\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0577 - accuracy: 0.9826 - val_loss: 0.0807 - val_accuracy: 0.9754\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9778\n",
            "Test accuracy: 0.9778000116348267\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUWBW4pPIge5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}